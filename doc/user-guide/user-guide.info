This is user-guide.info, produced by makeinfo version 4.8 from
user-guide.texi.

START-INFO-DIR-ENTRY
* GlusterFS: (user-guide). GlusterFS distributed filesystem user guide
END-INFO-DIR-ENTRY

   This is the user manual for GlusterFS 1.3.

   Copyright (C) 2007 Z Research, Inc. Permission is granted to copy,
distribute and/or modify this document under the terms of the GNU Free
Documentation License, Version 1.2 or any later version published by
the Free Software Foundation; with no Invariant Sections, no
Front-Cover Texts, and no Back-Cover Texts. A copy of the license is
included in the chapter entitled "GNU Free Documentation License".


File: user-guide.info,  Node: Top,  Next: Acknowledgements,  Up: (dir)

GlusterFS 1.3 User Guide
************************

This is the user manual for GlusterFS 1.3.

   Copyright (C) 2007 Z Research, Inc. Permission is granted to copy,
distribute and/or modify this document under the terms of the GNU Free
Documentation License, Version 1.2 or any later version published by
the Free Software Foundation; with no Invariant Sections, no
Front-Cover Texts, and no Back-Cover Texts. A copy of the license is
included in the chapter entitled "GNU Free Documentation License".

* Menu:

* Acknowledgements::
* Introduction::
* Installation and Invocation::
* Concepts::
* Translators::
* Usage Scenarios::
* Performance::
* Troubleshooting::
* GNU Free Documentation Licence::
* Index::

 --- The Detailed Node Listing ---

Installation and Invocation

* Pre requisites::
* Getting GlusterFS::
* Building::
* Running GlusterFS::
* A Tutorial Introduction::

Running GlusterFS

* Server::
* Client::

Concepts

* Filesystems in Userspace::
* Translator::
* Volume specification file::

Translators

* Storage Translators::
* Client and Server Translators::
* Clustering Translators::
* Performance Translators::
* Features Translators::
* Miscallaneous Translators::

Storage Translators

* POSIX::

Client and Server Translators

* Transport modules::
* Client protocol::
* Server protocol::

Clustering Translators

* Unify::
* Automatic File Replication::
* Stripe::

Performance Translators

* Read Ahead::
* Write Behind::
* IO Threads::
* IO Cache::

Features Translators

* POSIX Locks::
* Fixed ID::

Miscallaneous Translators

* ROT-13::
* Trace::


File: user-guide.info,  Node: Acknowledgements,  Next: Introduction,  Prev: Top,  Up: Top

Acknowledgements
****************

GlusterFS continues to be a wonderful and enriching experience for all
of us involved. Anand Babu conceived GlusterFS, and leads its
development.  The development team consists of Anand Avati, Amar
Tumballi, Basavanagowda Kanur, Harshavardhana Ranganath, Krishna
Srinivas, Raghavendra G, and myself. Our CEO, Hitesh Chellani, ensures
we get paid for hacking on GlusterFS.

   GlusterFS development would not have been possible at this pace if
not for our enthusiastic users. People from around the world have
helped us with bug reports, performance numbers, and feature
suggestions.  A huge thanks to them all.

   Matthew Paine - for RPMs & general enthu

   Leonardo Rodrigues de Mello - for DEBs

   Julian Perez & Adam D'Auria - for multi-server tutorial

   Paul England - for HA spec

   Brent Nelson - for many bug reports

   Jacques Mattheij - for europe mirror.

                                    Vikas Gorur (<vikas@zresearch.com>)
                                                             Z Research


File: user-guide.info,  Node: Introduction,  Next: Installation and Invocation,  Prev: Acknowledgements,  Up: Top

1 Introduction
**************

GlusterFS is a distributed filesystem. It works at the file level, not
block level.

   A network filesystem is one which allows us to access remote files. A
distributed filesystem is one that stores data on multiple machines and
makes them all appear to be a part of the same filesystem.

   Need for distributed filesystems

   * Scalability: A distributed filesystem allows us to store more data
     than what can be stored on a single machine.

   * Redundancy: We might want to replicate crucial data on to several
     machines.

   * Uniform access: One can mount a remote volume (for example your
     home directory) from any machine and access the same data.

1.1 Contacting us
=================

You can reach us through the mailing list *gluster-devel*
(<gluster-devel@nongnu.org>).  

   You can also find many of the developers on IRC, on the `#gluster'
channel on Freenode (<irc.freenode.net>).  

   For commercial support, you can contact Z Research at: 

     Z Research Inc.,
     3194 Winding Vista Common
     Fremont, CA 94539
     USA.
     Phone: +1-510-5346801
     Toll free: +18888136309

   You can also email us at <support@zresearch.com>.


File: user-guide.info,  Node: Installation and Invocation,  Next: Concepts,  Prev: Introduction,  Up: Top

2 Installation and Invocation
*****************************

* Menu:

* Pre requisites::
* Getting GlusterFS::
* Building::
* Running GlusterFS::
* A Tutorial Introduction::


File: user-guide.info,  Node: Pre requisites,  Next: Getting GlusterFS,  Up: Installation and Invocation

2.1 Pre requisites
==================

Before installing GlusterFS make sure you have the following components
installed.

2.1.1 FUSE
----------

You'll need FUSE version 2.6.0 or higher to use GlusterFS. You can omit
installing FUSE if you want to build _only_ the server. Note that you
won't be able to mount a GlusterFS filesystem on a machine that does
not have FUSE installed.

   FUSE can be downloaded from: <http://fuse.sourceforge.net/>

2.1.2 libibverbs (optional)
---------------------------

This is only needed if you want GlusterFS to use InfiniBand as the
interconnect mechanism between server and client. You can get it from:

   <http://www.openfabrics.org/downloads.htm>.

2.1.3 Bison and Flex
--------------------

These should be already installed on most Linux systems. We recommend
using GNU Bison and Flex.


File: user-guide.info,  Node: Getting GlusterFS,  Next: Building,  Prev: Pre requisites,  Up: Installation and Invocation

2.2 Getting GlusterFS
=====================

There are many ways to get hold of GlusterFS. For a production
deployment, the recommended method is to download the latest release
tarball.  Release tarballs are available at:
<http://gluster.org/download.php>.

   If you want the bleeding edge development source, you can get them
from the GNU Arch(1) repository. First you must install GNU Arch
itself. Then register the GlusterFS archive by doing:

     $ tla register-archive http://arch.sv.gnu.org/archives/gluster

   Now you can check out the source itself:

     $ tla get -A gluster@sv.gnu.org glusterfs--mainline--2.5

   If you are on an RPM based system, you can also try RPMs contributed
by Matthew Paine (<matt@mattsoftware.com>), for CentOS 5, available at:

   <http://www.mattsoftware.com/msw_repo/centos/5/>

   Leonardo Rodrigues de Mello (<l@lmello.eu.org>) has created Ubuntu
(Etch) packages of GlusterFS. They are available at:

<http://guialivre.governoeletronico.gov.br/guiaonline/downloads/pacotes-cluster/dists/etch/glusterfs/>

   ---------- Footnotes ----------

   (1) <http://www.gnu.org/software/gnu-arch/>


File: user-guide.info,  Node: Building,  Next: Running GlusterFS,  Prev: Getting GlusterFS,  Up: Installation and Invocation

2.3 Building
============

You can skip this section if you're installing from RPMs or DEBs.

   GlusterFS uses the Autotools mechanism to build. As such, the
procedure is straight-forward. First, change into the GlusterFS source
directory.

     $ cd glusterfs--1.3

   If you checked out the source from the Arch repository, you'll need
to run `./autogen.sh' first. Note that you'll need to have Autoconf and
Automake installed for this.

   Run `configure'.

     $ ./configure

   The configure script accepts the following options:

`--disable-ibverbs'
     Disable the InfiniBand transport mechanism.

`--disable-fuse-client'
     Disable the FUSE client.

`--disable-server'
     Disable building of the GlusterFS server.



File: user-guide.info,  Node: Running GlusterFS,  Next: A Tutorial Introduction,  Prev: Building,  Up: Installation and Invocation

2.4 Running GlusterFS
=====================

* Menu:

* Server::
* Client::


File: user-guide.info,  Node: Server,  Next: Client,  Up: Running GlusterFS

2.4.1 Server
------------

Lorem ipsum some text just to fill up

   things

   you kn

   know

`-f, --spec-file=VOLUMESPEC-FILE'
     Load the VOLUMESPEC-FILE.

`-l, --log-file=LOGFILE'
     Specify the file to redirect logs

`-L, --log-level=LOGLEVEL'
     LOGLEVEL should be one of DEBUG, WARNING, [ERROR], CRITICAL, NONE

`-N, --no-daemon'
     Run glusterfsd in foreground

`-p, --pidfile=PIDFILE'
     Path for the pid file

`-?, --help'
     Give this help list

`--usage'
     Give a short usage message

`-V, --version'
     display version information


File: user-guide.info,  Node: Client,  Prev: Server,  Up: Running GlusterFS

2.4.2 Client
------------

`-a, --attr-timeout=SECONDS'
     Attribute timeout for inodes in the kernel. Defaults to 1 second

`-d, --direct-io-mode=ENABLE|DISABLE'
     Whether to force directIO on fuse fd. Defaults to ENABLE

`-e, --entry-timeout=SECONDS'
     Entry timeout for dentries in the kernel. Defaults to 1 second

`-f, --spec-file=VOLUMESPEC-FILE'
     Load a local VOLUMESPEC file. Mandatory if -server option is not
     passed.

`-l, --log-file=LOGFILE'
     Specify the file to redirect logs

`-L, --log-level=LOGLEVEL'
     LOGLEVEL should be one of DEBUG, WARNING, [ERROR], CRITICAL, NONE

`-n, --volume-name=VOLUME-NAME'
     Volume name in client spec to use. Defaults to the topmost volume

`-N, --no-daemon'
     Run glusterfs in foreground

`-p, --port=PORT'
     Connect to PORT on SERVER

`-s, --server=SERVER'
     SERVER to connect to get client specification. One of -server or
     -spec-file is mandatory.

`-t, --transport=TRANSPORT'
     Transport type to get the spec from server

`-?, --help'
     Give this help list

`-V, --version'
     print version information


File: user-guide.info,  Node: A Tutorial Introduction,  Prev: Running GlusterFS,  Up: Installation and Invocation

2.5 A Tutorial Introduction
===========================

This section will show you how to quickly get GlusterFS up and running.
We'll configure GlusterFS as a simple network filesystem, with one
server and one client.  In this mode of usage, GlusterFS can serve as a
replacement for NFS.

   We'll make use of two machines; call them _server_ and _client_ (If
you don't want to setup two machines, just run everything that follows
on the same machine).  In the examples that follow, the shell prompts
will use these names to clarify the machine on which the command is
being run. For example, a command that should be run on the server will
be shown with the prompt:

     [root@server]#

   Our goal is to make a directory on the _server_ (say, `/export')
accessible to the _client_.

   First of all, get GlusterFS installed on both the machines, as
described in the previous sections. Make sure you have the FUSE kernel
module loaded. You can ensure this by running:

     [root@server]# modprobe fuse

   Before we can run the GlusterFS client or server programs, we need
to write two files called _volume specifications_. The volume spec
describes the _translator tree_ on a node. The next chapter will
explain the concepts of `translator' and `volume specification' in
detail. For now, just assume that the volume spec is like an NFS
`/etc/export' file.

   On the server, create a text file somewhere (we'll assume the path
`/tmp/glusterfs-server.vol') with the following contents.

     volume colon-o
       type storage/posix
       option directory /export
     end-volume

     volume server
       type protocol/server
       subvolumes colon-o
       option transport-type tcp/server
       option auth.addr.colon-o.allow *
     end-volume

   A brief explanation of the file's contents. The first section
defines a storage volume, named "colon-o" (the volume names are
arbitrary), which exports the `/export' directory. The second section
defines options for the translator which will make the storage volume
accessible remotely. It specifies `colon-o' as a subvolume. This
defines the _translator tree_, about which more will be said in the
next chapter. The two options specify that the TCP protocol is to be
used (as opposed to InfiniBand, for example), and that access to the
storage volume is to be provided to clients with any IP address at all.
If you wanted to restrict access to this server to only your subnet for
example, you'd specify something like `192.168.1.*' in the second
option line.

   On the client machine, create the following text file (again, we'll
assume the path to be `/tmp/glusterfs-client.vol'). Replace
_server-ip-address_ with the IP address of your server machine. If you
are doing all this on a single machine, use `127.0.0.1'.

     volume client
       type protocol/client
       option transport-type tcp/client
       option remote-host _server-ip-address_
       option remote-subvolume colon-o
     end-volume

   Now we need to start both the server and client programs. To start
the server:

     [root@server]# glusterfsd -f /tmp/glusterfs-server.vol

   To start the client:

     [root@client]# glusterfs -f /tmp/glusterfs-client.vol /mnt/glusterfs

   You should now be able to see the files under the server's `/export'
directory in the `/mnt/glusterfs' directory on the client. That's it,
GlusterFS is now working as a network file system.


File: user-guide.info,  Node: Concepts,  Next: Translators,  Prev: Installation and Invocation,  Up: Top

3 Concepts
**********

* Menu:

* Filesystems in Userspace::
* Translator::
* Volume specification file::


File: user-guide.info,  Node: Filesystems in Userspace,  Next: Translator,  Up: Concepts

3.1 Filesystems in Userspace
============================

                       Control flow in GlusterFS

   A filesystem is usually implemented in the kernel. Kernel
development is much harder than userspace development. FUSE is a kernel
module/library that allows us to write a filesystem completely in
userspace.

   FUSE consists of a kernel module which interacts with the userspace
implementation using a device file `/dev/fuse'. When a process makes a
syscall on a FUSE filesystem, VFS hands the request to the FUSE module,
which writes the request to `/dev/fuse'. The userspace implementation
polls `/dev/fuse', and when a request arrives, processes it and writes
the result back to `/dev/fuse'. The kernel then reads from the device
file and returns the result to the user process.

   application -> kernel -> fuse -> /dev/fuse -> user process  ->
server -> underlying filesystem

       	       	   |   	       User space
		   |
   Server machine  | Client machine	   	  +-------------+
		   |			   	  | Application	|
       	     	   |             	   	  +-------------+
+-----------+ TCP  |  +---------+	       	         |
| GlusterFS |=========|GlusterFS| 	   	     	 |
|  server   | or IB|  |	client 	| 	   	     	 |
+-----------+ 	   |  +---------+ 	   	     	 | system
   | 		   |   	  ^		   	     	 | call
---|---------------|------|------------------------------|------------
   | 		   |   	  |    	       	       	     	 |
   v 		   |  	  |		   	     	 |
+-----+	       	   |   	  |                    	         v
| VFS |	       	   |   +---------+   +-----+	     +-----+
+-----+	       	   |   |/dev/fuse|<--|FUSE |<--------| VFS |
   |  		   |   +---------+   +-----+   	     +-----+
   v               |
+----+		   |
|ext3|         	   |
+----+		   |	       Kernel space


File: user-guide.info,  Node: Translator,  Next: Volume specification file,  Prev: Filesystems in Userspace,  Up: Concepts

3.2 Translator
==============

The _translator_ is the most important concept in GlusterFS. In fact,
GlusterFS is nothing but a collection of translators working together,
forming a translator _tree_.

   The idea of a translator is perhaps best understood using an
analogy. Consider the VFS in the Linux kernel. The VFS abstracts the
various filesystem implementations (such as ext3, ReiserFS, xfs, etc.)
supported by the kernel. When an application calls the kernel to
perform an operation on a file, the kernel passes the request on to the
appropriate filesystem implementation.

   For example, let's say there are two partitions on a Linux machine:
`/', which is an ext3 partition, and `/usr', which is a ReiserFS
partition. Now if an application wants to open a file called, say,
`/etc/fstab', then the kernel will internally pass the request to the
ext3 implementation.  If on the other hand, an application wants to
read a file called `/usr/src/linux/CREDITS', then the kernel will call
upon the ReiserFS implementation to do the job.

   The "filesystem implementation" objects are analogous to GlusterFS
translators. A GlusterFS translator implements all the filesystem
operations.  Whereas in VFS there is a two-level tree (with the kernel
at the root and all the filesystem implementation as its children), in
GlusterFS there exists a more elaborate tree structure.

   We can now define translators more precisely. A GlusterFS translator
is a shared object (`.so') that implements every filesystem call.
GlusterFS translators can be arranged in an arbitrary tree structure
(subject to constraints imposed by the translators). When GlusterFS
receives a filesystem call, it passes it on to the translator at the
root of the translator tree. The root translator may in turn pass it on
to any or all of its children, and so on, until the leaf nodes are
reached. The result of a filesystem call is communicated in the reverse
fashion, from the leaf nodes up to the root node, and then on to the
application.

   So what might a translator tree look like?


File: user-guide.info,  Node: Volume specification file,  Prev: Translator,  Up: Concepts

3.3 Volume specification file
=============================


File: user-guide.info,  Node: Translators,  Next: Usage Scenarios,  Prev: Concepts,  Up: Top

4 Translators
*************

* Menu:

* Storage Translators::
* Client and Server Translators::
* Clustering Translators::
* Performance Translators::
* Features Translators::
* Miscallaneous Translators::


File: user-guide.info,  Node: Storage Translators,  Next: Client and Server Translators,  Up: Translators

4.1 Storage Translators
=======================

The storage translators form the "backend" for GlusterFS. Currently,
the only available storage translator is the POSIX translator, which
stores files on a normal POSIX filesystem. A pleasant consequence of
this is that your data will still be accessible if GlusterFS crashes or
cannot be started.

   Other storage backends are planned for the future. One of the
possibilities is an Amazon S3 translator. Amazon S3 is an unlimited
online storage service accessible through a web services API. The S3
translator will allow you to access the storage as a normal POSIX
filesystem.  (1)

* Menu:

* POSIX::

   ---------- Footnotes ----------

   (1) Some more discussion about this can be found at:

http://developer.amazonwebservices.com/connect/message.jspa?messageID=52873


File: user-guide.info,  Node: POSIX,  Up: Storage Translators

4.1.1 POSIX
-----------

     type storage/posix

   The `posix' translator uses a normal POSIX filesystem as its
"backend" to actually store files and directories. This can be any
filesystem that supports extended attributes (EXT3, ReiserFS, XFS,
...). Extended attributes are used by some translators to store
metadata, for example, by the AFR and stripe translators. See *Note
Automatic File Replication:: and *Note Stripe::, respectively for
details.

`directory <path>'
     The directory on the local filesytem which is to be used for
     storage.

`inode-lru-limit <n> (1000)'


File: user-guide.info,  Node: Client and Server Translators,  Next: Clustering Translators,  Prev: Storage Translators,  Up: Translators

4.2 Client and Server Translators
=================================

The client and server translator enable GlusterFS to export a
translator tree over the network or access a remote GlusterFS server.
These two translators implement GlusterFS's network protocol.

* Menu:

* Transport modules::
* Client protocol::
* Server protocol::


File: user-guide.info,  Node: Transport modules,  Next: Client protocol,  Up: Client and Server Translators

4.2.1 Transport modules
-----------------------

The client and server translators are capable of using any of the
pluggable transport modules. Currently available transport modules are
`tcp', which uses a TCP connection between client and server to
communicate; `ib-sdp', which uses a TCP connection over InfiniBand, and
`ibverbs', which uses high-speed InfiniBand connections.


File: user-guide.info,  Node: TCP

4.2.1.1 TCP
...........

`non-blocking-connect [no|off|on|yes] (on)'

`remote-port <n> (6996)'

`remote-host <hostname> *'


File: user-guide.info,  Node: IB-SDP

4.2.1.2 IB-SDP
..............

kernel implements socket interface for ib hardware. SDP is over
ib-verbs.  This module accepts the same options as `tcp'


File: user-guide.info,  Node: ibverbs

4.2.1.3 ibverbs
...............

The `ib-verbs' transport accesses the InfiniBand hardware through the
"verbs" API, which is the lowest level of software access possible and
which gives the highest performance. On InfiniBand hardware, it is
always best to use `ib-verbs'. Use `ib-sdp' only if you cannot get
`ib-verbs' working for some reason.

   If you are familiar with InfiniBand jargon, the mode is used by
GlusterFS is "reliable connection-oriented channel transfer".

   (Mellanox notes).

   The `ib-verbs' transport module accepts the following options.

`ib-verbs-work-request-send-count <n> (64)'
     Length of the send queue in datagrams. [Reason to
     increase/decrease?]

`ib-verbs-work-request-recv-count <n> (64)'
     Length of the receive queue in datagrams. [Reason to
     increase/decrease?]

`ib-verbs-work-request-send-size <size> (128KB)'
     Size of each datagram that is sent. [Reason to increase/decrease?]

`ib-verbs-work-request-recv-size <size> (128KB)'
     Size of each datagram that is received. [Reason to
     increase/decrease?]

`ib-verbs-port <n> (1)'
     Port number for ib-verbs.

`ib-verbs-mtu [256|512|1024|2048|4096] (2048)'
     The Maximum Transmission Unit [Reason to increase/decrease?]

`ib-verbs-device-name <device-name> (first device in the list)'
     InfiniBand device to be used.

   For maximum performance, you should ensure that the send/receive
counts on both the client and server are the same.

   ib-verbs is preferred over ib-sdp.


File: user-guide.info,  Node: Client protocol,  Next: Server protocol,  Prev: Transport modules,  Up: Client and Server Translators

4.2.2 Client
------------

     type procotol/client

   client protocol.

`transport-type [tcp,ib-sdp,ib-verbs] (tcp/client)'

`remote-subvolume <volume_name> *'

`inode-lru-limit <n> (1000)'

`transport-timeout <n> (120- seconds)'


File: user-guide.info,  Node: Server protocol,  Prev: Client protocol,  Up: Client and Server Translators

4.2.3 Server
------------

     type protocol/server

`client-volume-filename <path> (<CONFDIR>/glusterfs-client.vol)'

`transport-type [tcp,ib-verbs,ib-sdp] (tcp/server)'


File: user-guide.info,  Node: Clustering Translators,  Next: Performance Translators,  Prev: Client and Server Translators,  Up: Translators

4.3 Clustering Translators
==========================

* Menu:

* Unify::
* Automatic File Replication::
* Stripe::


File: user-guide.info,  Node: Unify,  Next: Automatic File Replication,  Up: Clustering Translators

4.3.1 Unify
-----------

     type cluster/unify

   unify unifies its subvolumes.  it has children, and will do stuff on
them.

   scheduler is used for creates.   rr, random  nufa - prefers local.
otherwise does rr  alu - adaptive least usage. Various criteria. order
of preference. entry & exit        threshold.

4.3.1.1 ALU
...........

ALU stands for "Adaptive Least Usage". It is the most advanced
scheduler available in GlusterFS. It balances the load across volumes,
taking several factors in account. It adapts itself to changing I/O
patterns, according to its configuration. When properly configured, it
can eliminate the need for regular tuning of the filesystem to keep
volume load nicely balanced.

   The ALU scheduler is composed of multiple least-usage
sub-schedulers. Each sub-scheduler keeps track of a certain type of
load, for each of the subvolumes, getting the actual statistics from
the subvolumes themselves. The sub-schedulers are these:

   disk-usage - the used and free disk space on the volume

   read-usage - the amount of reading done from this volume

   write-usage - the amount of writing done to this volume

   open-files-usage - the number of files currently opened from this
volume

   disk-speed-usage - the speed at which the disks are spinning. This is
a constant value and therefore not very useful.

   The ALU scheduler needs to know which of these sub-schedulers to use,
and in which order to evaluate them. This is done through the `option
alu.order' configuration directive.

   Each sub-scheduler needs to know two things: when to kick in (the
entry-threshold), and how long to stay in control (the exit-threshold).
For example: when unifying three disks of 100GB, keeping an exact
balance of disk-usage is not necesary. Instead, there could be a 1GB
margin, which can be used to nicely balance other factors, such as
read-usage. The disk-usage scheduler can be told to kick in only when a
certain threshold of discrepancy is passed, such as 1GB. When it
assumes control under this condition, it will write all subsequent data
to the least-used volume. If it is doing so, it is unwise to stop right
after the values are below the entry-threshold again, since that would
make it very likely that the situation will occur again very soon. Such
a situation would cause the ALU to spend most of its time disk-usage
scheduling, which is unfair to the other sub-schedulers. The
exit-threshold therefore defines the amount of data that needs to be
written to the least-used disk, before control is relinquished again.

   In addition to the sub-schedulers, the ALU scheduler also has
"limits" options. These can stop the creation of new files on a volume
once values drop below a certain threshold. For example, setting "option
alu.limits.min-free-disk 5GB" will stop the scheduling of files to
volumes that have less than 5GB of free disk space, leaving the files
on that disk some room to grow.

   The actual values you assign to the thresholds for sub-schedulers and
limits depend on your situation. If you have fast-growing files, you'll
want to stop file-creation on a disk much earlier than when hardly any
of your files are growing. If you care less about disk-usage balance
than about read-usage balance, you'll want a bigger disk-usage
scheduler entry-threshold and a smaller read-usage scheduler
entry-threshold.

   For thresholds defining a size, values specifying "KB", "MB" and "GB"
are allowed. For example: `option alu.limits.min-free-disk 5GB'.

`alu.order <order> * ("disk-usage:write-usage:read-usage:open-files-usage:disk-speed")'

`alu.disk-usage.entry-threshold <size> (1GB)'

`alu.disk-usage.exit-threshold <size> (512MB)'

`alu.write-usage.entry-threshold <%> (25)'

`alu.write-usage.exit-threshold <%> (5)'

`alu.read-usage.entry-threshold <%> (25)'

`alu.read-usage.exit-threshold <%> (5)'

`alu.open-files-usage.entry-threshold <n> (1000)'

`alu.open-files-usage.exit-threshold <n> (100)'

`alu.limits.min-free-disk <%>'

`alu.limits.max-open-files <n>'

4.3.1.2 Round Robin (RR)
........................

Round-Robin (RR) scheduler creates files in a round-robin fashion. Each
client will have its own round-robin loop. When your files are mostly
similar in size and I/O access pattern, this scheduler is a good
choice. RR scheduler now checks for free disk size of the server before
scheduling, so you can know when to add another server brick. The
default value of min-free-disk is 5% and is checked every 10 seconds
(by default) if there is any create call happening.

`rr.limits.min-free-disk <%> (5)'

`rr.refresh-interval <t> (10 seconds)'

`random.limits.min-free-disk <%> (5)'

`random.refresh-interval <t> (10 seconds)'

4.3.1.3 NUFA
............

Non-Uniform Filesystem Scheduler similar to NUMA (1) memory design. It
is mainly used in HPC environments where you are required to run the
filesystem server and client within the same cluster. Under such
environment, NUFA scheduler gives the local system first priority for
file creation over other nodes.

`nufa.limits.min-free-disk <%> (5)'

`nufa.refresh-interval <t> (10 seconds)'

`nufa.local-volume-name <volume>'

   Namespace volume needed because:  - persistent inode numbers.   -
file exists even when node is down.

   namespace files are simply touched. on every lookup it is checked.

   Self heal:  two rules:    - dir structure should be consistent.
- file should exist on only one node.

`namespace <volume> *'

`self-heal [on|off] (on)'

`inode-lru-limit <n> (1000)'

   ---------- Footnotes ----------

   (1) http://en.wikipedia.org/wiki/Non-Uniform_Memory_Access


File: user-guide.info,  Node: Automatic File Replication,  Next: Stripe,  Prev: Unify,  Up: Clustering Translators

4.3.2 Automatic File Replication (AFR)
--------------------------------------

     type cluster/afr

   Replication is via PATTERN:N. Extended attributes needed for self
heal functionality. Version number and ctime is stored in the
attributes.

   All of this not recommended: If you increase n, new file will be
created.  If you decrease n, nothing happens.

   If you change subvolume order, it asserts that the first n
*available* (nodes which are up) subvolumes have the file.

   If a file is missing on a node, the latest version available will be
written there. Missing directories are created during lookup.

   self heal happens on open.

   subvolume list must be same on all clients. Recommended
configuration is to have exact same spec. Use -s.

`debug [on|off]  (off)'

`self-heal [on|off] (on)'

`replicate <pattern> (*:1)'

`lock-node <child_volume> (first_child)'

`inode-lru-limit <n> (1000)'


File: user-guide.info,  Node: Stripe,  Prev: Automatic File Replication,  Up: Clustering Translators

4.3.3 Stripe
------------

     type cluster/stripe

   uses extended attrs to store info.

`inode-lru-limit <n> (1000)'

`block-size <pattern> (*:0 no striping)'


File: user-guide.info,  Node: Performance Translators,  Next: Features Translators,  Prev: Clustering Translators,  Up: Translators

4.4 Performance Translators
===========================

* Menu:

* Read Ahead::
* Write Behind::
* IO Threads::
* IO Cache::


File: user-guide.info,  Node: Read Ahead,  Next: Write Behind,  Up: Performance Translators

4.4.1 Read Ahead
----------------

     type performance/read-ahead

   The read-ahead translator pre-fetches data in advance on every read.
This benefits applications that mostly process files in sequential
order, since the next block of data will already be available by the
time the application is done with the current one.

   Additionally, the read-ahead translator also behaves as a
read-aggregator.  Many small read operations are combined and issued as
fewer, larger read requests to the server.

   Read-ahead deals in "pages" as the unit of data fetched. The page
size is configurable, as is the "page count", which is the number of
pages that are pre-fetched.

   Read-ahead is best used with InfiniBand (using the ib-verbs
transport, *note ibverbs::). On FastEthernet and Gigabit Ethernet
networks, GlusterFS can achieve the link-maximum throughput even without
read-ahead, making it quite superflous.

   Note that read-ahead only happens if the reads are perfectly
sequential. If your application accesses data in a random fashion,
using read-ahead might actually lead to a performance loss, since
read-ahead will pointlessly fetch pages which won't be used by the
application.

   Options:
`page-size <n> (256KB)'
     The unit of data that is pre-fetched.

`page-count <n> (2)'
     The number of pages that are pre-fetched.

`force-atime-update [on|off|yes|no] (off|no)'
     Whether to force an access time (atime) update on the file on
     every read. Without this, the atime will be slightly imprecise, as
     it will reflect the time when the read-ahead translator read the
     data, not when the application actually read it.


File: user-guide.info,  Node: Write Behind,  Next: IO Threads,  Prev: Read Ahead,  Up: Performance Translators

4.4.2 Write Behind
------------------

     type performance/write-behind

   The write-behind translator improves the latency of a write
operation.  It does this by relegating the write operation to the
background and returning to the application even as the write is in
progress. Using the write-behind translator, successive write requests
can be pipelined.  This mode of write-behind operation is best used on
the client side, to enable decreased write latency for the application.

   The write-behind translator can also aggregate write requests. If the
`aggregate-size' option is specified, then successive writes upto that
size are accumulated and written in a single operation. This mode of
operation is best used on the server side, as this will decrease the
disk's head movement when multiple files are being written to in
parallel.

   The `aggregate-size' option has a default value of 128KB. Although
this works well for most users, you should always experiment with
different values to determine the one that will deliver maximum
performance. This is because the performance of write-behind depends on
your interconnect, size of RAM, and the work load.

`aggregate-size <n> (128KB)'
     Amount of data to accumulate before doing a write

`flush-behind [on|yes|off|no] (off|no)'


File: user-guide.info,  Node: IO Threads,  Next: IO Cache,  Prev: Write Behind,  Up: Performance Translators

4.4.3 IO Threads
----------------

     type performance/io-threads

   The IO threads translator is intended to increase the responsiveness
of the server to metadata operations by doing file I/O (read, write) in
a background thread.  Since the GlusterFS server is single-threaded,
using the IO threads translator can significantly improve performance.
This translator is best used on the server side, loaded just below the
server protocol translator.

   IO threads operates by handing out read and write requests to a
separate thread.  The total number of threads in existence at a time is
constant, and configurable.  You can also set a maximum limit on the
amount of data to be queued with IO threads, using the `cache-size'
option. If more than `cache-size' worth of operations are pending, any
further requests will block.

`thread-count <n> (1)'
     Number of threads to use.

`cache-size <n> (64MB)'
     Maximum amount of data allowed to be pending inside io-threads.


File: user-guide.info,  Node: IO Cache,  Prev: IO Threads,  Up: Performance Translators

4.4.4 IO Cache
--------------

     type performance/io-cache

   The IO cache translator caches data that has been read. This is
useful if many applications read the same data multiple times, and if
reads are much more frequent than writes (for example, IO caching may be
useful in a web hosting environment, where most clients will simply
read some files and only a few will write to them).

   The IO cache translator reads data from its child in `page-size'
chunks.  It caches data upto `cache-size' bytes. The cache is
maintained as a prioritized least-recently-used (LRU) list, with
priorities determined by user-specified patterns to match filenames.

   When the IO cache translator detects a write operation, the cache
for that file is flushed.

   The IO cache translator periodically verifies the consistency of
cached data, using the modification times on the files. The
verification timeout is configurable.

`page-size <n> (128KB)'
     Size of a page.

`cache-size (n) (32MB)'
     Total amount of data to be cached.

`force-revalidate-timeout <n> (1)'
     Timeout to force a cache consistency verification, in seconds.

`priority <pattern> (*:0)'
     Filename patterns listed in order of priority.

4.4.5 Booster
-------------


File: user-guide.info,  Node: Booster

       type performance/booster

   The booster translator gives applications a faster path to
communicate read and write requests to GlusterFS. Normally, all
requests to GlusterFS from applications go through FUSE, as indicated
in *Note Filesystems in Userspace::.  Using the booster translator in
conjunction with the GlusterFS booster shared library, an application
can bypass the FUSE path and send read/write requests directly to the
GlusterFS client process.

   The booster mechanism consists of two parts: the booster translator,
and the booster shared library. The booster translator is meant to be
loaded on the client side, usually at the root of the translator tree.
The booster shared library should be `LD_PRELOAD'ed with the
application.

   The booster translator when loaded opens a Unix domain socket and
listens for read/write requests on it. The booster shared library
intercepts read and write system calls and sends the requests to the
GlusterFS process directly using the Unix domain socket, bypassing FUSE.
This leads to superior performance.

   Once you've loaded the booster translator in your volume
specification file, you can start your application as:

       $ LD_PRELOAD=/usr/local/bin/glusterfs-booster.so your_app

   The booster translator accepts no options.


File: user-guide.info,  Node: Features Translators,  Next: Miscallaneous Translators,  Prev: Performance Translators,  Up: Translators

4.5 Features Translators
========================

* Menu:

* POSIX Locks::
* Fixed ID::


File: user-guide.info,  Node: POSIX Locks,  Next: Fixed ID,  Up: Features Translators

4.5.1 POSIX Locks
-----------------

     type features/posix-locks

   This translator provides storage independent POSIX record locking
support (fcntl locking). Typically you'll want to load this on the
server side, just above the POSIX storage translator. Using this
translator you can get both advisory locking and mandatory locking
support.  `flock()' locks are currently not supported.

   Caveat: Consider a file that does not have its mandatory locking bits
(+setgid, -group execution) turned on. Assume that this file is now
opened by a process on a client that has the write-behind xlator
loaded. The write-behind xlator does not cache anything for files which
have mandatory locking enabled, to avoid incoherence. Let's say that
mandatory locking is now enabled on this file through another client.
The former client will not know about this change, and write-behind may
erroneously report a write as being successful when in fact it would
fail due to the region it is writing to being locked.

   There seems to be no easy way to fix this. To work around this
problem, it is recommended that you never enable the mandatory bits on
a file while it is open.

`mandatory [on|off] (on)'
     Turns mandatory locking on.


File: user-guide.info,  Node: Fixed ID,  Prev: POSIX Locks,  Up: Features Translators

4.5.2 Fixed ID
--------------

     type features/fixed-id

   The fixed ID translator makes all filesystem requests from the client
to appear to be coming from a fixed, specified UID/GID, regardless of
which user actually initiated the request.

`fixed-uid <n> [if not set, not used]'
     The UID to send to the server

`fixed-gid <n> [if not set, not used]'
     The GID to send to the server


File: user-guide.info,  Node: Miscallaneous Translators,  Prev: Features Translators,  Up: Translators

4.6 Miscallaneous Translators
=============================

* Menu:

* ROT-13::
* Trace::


File: user-guide.info,  Node: ROT-13,  Next: Trace,  Up: Miscallaneous Translators

4.6.1 ROT-13
------------

     type encryption/rot-13

   ROT-13 is a toy translator that can "encrypt" and "decrypt" file
contents using the ROT-13 algorithm. ROT-13 is a trivial algorithm that
rotates each alphabet by thirteen places. Thus, 'A' becomes 'N', 'B'
becomes 'O', and 'Z' becomes 'M'.

   It goes without saying that you shouldn't use this translator if you
need _real_ encryption (a future release of GlusterFS will have real
encryption translators).

`encrypt-write [on|off] (on)'
     Whether to encrypt on write

`decrypt-read [on|off] (on)'
     Whether to decrypt on read


File: user-guide.info,  Node: Trace,  Prev: ROT-13,  Up: Miscallaneous Translators

4.6.2 Trace
-----------

     type debug/trace

   The trace translator is intended for debugging purposes. When
loaded, it logs all the system calls received by the server or client
(wherever trace is loaded), their arguments, and the results. You must
use a GlusterFS log level of DEBUG (See *Note Running GlusterFS::) for
trace to work.

   Sample trace output (lines have been wrapped for readability):
     2007-10-30 00:08:58 D [trace.c:1579:trace_opendir] trace: callid: 68
     (*this=0x8059e40, loc=0x8091984 {path=/iozone3_283, inode=0x8091f00},
      fd=0x8091d50)

     2007-10-30 00:08:58 D [trace.c:630:trace_opendir_cbk] trace:
     (*this=0x8059e40, op_ret=4, op_errno=1, fd=0x8091d50)

     2007-10-30 00:08:58 D [trace.c:1602:trace_readdir] trace: callid: 69
     (*this=0x8059e40, size=4096, offset=0 fd=0x8091d50)

     2007-10-30 00:08:58 D [trace.c:215:trace_readdir_cbk] trace:
     (*this=0x8059e40, op_ret=0, op_errno=0, count=4)

     2007-10-30 00:08:58 D [trace.c:1624:trace_closedir] trace: callid: 71
     (*this=0x8059e40, *fd=0x8091d50)

     2007-10-30 00:08:58 D [trace.c:809:trace_closedir_cbk] trace:
     (*this=0x8059e40, op_ret=0, op_errno=1)


File: user-guide.info,  Node: Usage Scenarios,  Next: Performance,  Prev: Translators,  Up: Top

5 Usage scenarios
*****************

- usage as network filesystem - clustering with four bricks (Julian
Perez example, multi-server config example)

5.1 Advanced Striping
=====================

5.1.1 Mixed Storage Requirements
--------------------------------

There are two ways of scheduling the I/O. One at file level (using
unify translator) and other at block level (using stripe translator).
Striped I/O is good for files that are potentially large and require
high parallel throughput (for example, a single file of 400GB being
accessed by 100s and 1000s of systems simultaneously and randomly). For
most of the cases, file level scheduling works best.

   In the real world, it is desirable to mix file level and block level
scheduling on a single storage volume. Alternatively users can choose
to have two separate volumes and hence two mount points, but the
applications may demand a single storage system to host both.

   This document explains how to mix file level scheduling with stripe.

5.1.2 Configuration Brief
-------------------------

This setup demonstrates how users can configure unify translator with
appropriate I/O scheduler for file level scheduling and strip for only
matching patterns. This way, GlusterFS chooses appropriate I/O profile
and knows how to efficiently handle both the types of data.

   A simple technique to achieve this effect is to create a stripe set
of unify and stripe blocks, where unify is the first sub-volume. Files
that do not match the stripe policy passed on to first unify sub-volume
and inturn scheduled arcoss the cluster using its file level I/O
scheduler.

5.1.3 Preparing GlusterFS Envoronment
-------------------------------------

Create the directories /export/namespace, /export/unify and
/export/stripe on all the storage bricks.

   Place the following server and client volume spec file under
/etc/glusterfs (or appropriate installed path) and replace the IP
addresses / access control fields to match your environment.

       ## file: /etc/glusterfs/glusterfs-server.vol
        volume posix-unify
                type storage/posix
                option directory /export/for-unify
        end-volume

        volume posix-stripe
                type storage/posix
                option directory /export/for-stripe
        end-volume

        volume posix-namespace
                type storage/posix
                option directory /export/for-namespace
        end-volume

        volume server
                type protocol/server
                option transport-type tcp/server
                option auth.addr.posix-unify.allow 192.168.1.*
                option auth.addr.posix-stripe.allow 192.168.1.*
                option auth.addr.posix-namespace.allow 192.168.1.*
                subvolumes posix-unify posix-stripe posix-namespace
        end-volume

      ## file: /etc/glusterfs/glusterfs-client.vol
        volume client-namespace
          type protocol/client
          option transport-type tcp/client
          option remote-host 192.168.1.1
          option remote-subvolume posix-namespace
        end-volume

        volume client-unify-1
          type protocol/client
          option transport-type tcp/client
          option remote-host 192.168.1.1
          option remote-subvolume posix-unify
        end-volume

        volume client-unify-2
          type protocol/client
          option transport-type tcp/client
          option remote-host 192.168.1.2
          option remote-subvolume posix-unify
        end-volume

        volume client-unify-3
          type protocol/client
          option transport-type tcp/client
          option remote-host 192.168.1.3
          option remote-subvolume posix-unify
        end-volume

        volume client-unify-4
          type protocol/client
          option transport-type tcp/client
          option remote-host 192.168.1.4
          option remote-subvolume posix-unify
        end-volume

        volume client-stripe-1
          type protocol/client
          option transport-type tcp/client
          option remote-host 192.168.1.1
          option remote-subvolume posix-stripe
        end-volume

        volume client-stripe-2
          type protocol/client
          option transport-type tcp/client
          option remote-host 192.168.1.2
          option remote-subvolume posix-stripe
        end-volume

        volume client-stripe-3
          type protocol/client
          option transport-type tcp/client
          option remote-host 192.168.1.3
          option remote-subvolume posix-stripe
        end-volume

        volume client-stripe-4
          type protocol/client
          option transport-type tcp/client
          option remote-host 192.168.1.4
          option remote-subvolume posix-stripe
        end-volume

        volume unify
          type cluster/unify
          option scheduler rr
          subvolumes cluster-unify-1 cluster-unify-2 cluster-unify-3 cluster-unify-4
        end-volume

        volume stripe
          type cluster/stripe
          option block-size *.img:2MB # All files ending with .img are striped with 2MB stripe block size.
          subvolumes unify cluster-stripe-1 cluster-stripe-2 cluster-stripe-3 cluster-stripe-4
        end-volume

   Bring up the Storage

   Starting GlusterFS Server: If you have installed through binary
package, you can start the service through init.d startup script. If
not:

     [root@server]# glusterfsd

   Mounting GlusterFS Volumes:

     [root@client]# glusterfs -s [BRICK-IP-ADDRESS] /mnt/cluster

   Improving upon this Setup

   Infiniband Verbs RDMA transport is much faster than TCP/IP GigE
transport.

   Use of performance translators such as read-ahead, write-behind,
io-cache, io-threads, booster is recommended.

   Replace round-robin (rr) scheduler with ALU to handle more dynamic
storage environments.

5.2 High Availability setup
===========================

- HA setup (from HA tutorial by Paul England)

   - encrypted glusterfs setup using ssh tunnels.

   - Vserver guest (actually need a better organization for both
tunneled setup and vserver thing)


File: user-guide.info,  Node: Performance,  Next: Troubleshooting,  Prev: Usage Scenarios,  Up: Top

6 Performance
*************

- effect of direct_io mode.

6.1 glfs4 patched fuse
======================

channel size between fuse kernel module and libfuse tuned to 1MB

   kernel read-ahead boundry extended upto 1MB

   st_blksize returned in stat()/fstat() tuned to 1MB, to make cp and
similar commands perform I/O in that block size

   flock() locking support [note: needs some rework in glusterfs for
perfect compliance]

6.2 DNS failover
================

GlusterFS client will try connecting to all the IP addresses of a
hostname in round-robin fashion. Using this you can implement failover.


File: user-guide.info,  Node: Troubleshooting,  Next: GNU Free Documentation Licence,  Prev: Performance,  Up: Top

7 Troubleshooting
*****************

7.1 GlusterFS error messages
============================


File: user-guide.info,  Node: GlusterFS error messages

7.1.1 Server errors
-------------------


File: user-guide.info,  Node: Server errors

     glusterfsd: FATAL: could not open specfile:
     '/etc/glusterfs/glusterfs-server.vol'

   glusterfsd server requires volume specification file under
/etc/glusterfs/glusterfs-server.vol. Default installation will only
provide /etc/glusterfs/glusterfs-server.vol.sample sample file. You
need to copy it to /etc/glusterfs/glusterfs-server.vol actual file.

     gf_log_init: failed to open logfile "/usr/var/log/glusterfs/glusterfsd.log"
                  (Permission denied)

   Check if you are running as root user. Use 'whoami' utility.

7.1.2 Client errors
-------------------


File: user-guide.info,  Node: Client errors

      fusermount: failed to access mountpoint /mnt:
                  Transport endpoint is not connected

   umount /mnt and mount again.

   Error "Transport endpoint is not connected"

   GlusterFS mount failed. Start glusterfs client in DEBUG mode and
look out for descriptive error messages.

   connect to server failed

   SERVER-ADDRESS: Connection refused

   GluserFS Server is not running or dead. Also check your network
connections or firewall settings. To check if the server is reachable,
try the following command:

   telnet IP-ADDRESS 6996

   If server is accessible, your 'telnet' command should connect and
block. If not you will see an error message like telnet: Unable to
connect to remote host: Connection refused. '6996' is the default
GlusterFS port. If you have customized it, then use the corresponding
port instead.

   gf_log_init: failed to open logfile
"/usr/var/log/glusterfs/glusterfs.log" (Permission denied)

   glusterfs: failed to open logfile
"/usr/var/log/glusterfs/glusterfs.log"

   Check if you are running as root user. Use 'whoami' utility.

7.2 FUSE error messages
=======================

`modprobe' fuse fails with "Unknown symbol in module, or unknown
parameter".  

   If you are using fuse-2.6.x on Redhat Enterprise Linux Work Station 4
and Advanced Server 4 with 2.6.9-42.ELlargesmp, 2.6.9-42.ELsmp,
2.6.9-42.EL kernels and get this error while loading fuse kernel
module, you need to apply the following patch.

   For fuse-2.6.2:

<http://ftp.zresearch.com/pub/gluster/glusterfs/fuse/fuse-2.6.2-rhel-build.patch>

   For fuse-2.6.3:

<http://ftp.zresearch.com/pub/gluster/glusterfs/fuse/fuse-2.6.3-rhel-build.patch>

7.3 AppArmour and GlusterFS
===========================

Under OpenSuSE GNU/Linux, AppArmour security feature did not allow
GlusterFS to create temporary files or network socket connection even
as root user. You will see the error messages like Unable to open log
file: Operation not permitted or Connection refused error. Disabling
apparmour using YaST tool or properly configuring apparmour to
recognize glusterfsd or glusterfs / fusermount should solve the problem.

   GlusterFS log files.

7.4 Reporting a bug
===================

If you encounter a bug in GlusterFS, please follow the below guidelines
when you report it to the mailing list. Be sure to report it! User
feedback is crucial to the health of the project and we value it highly.

7.4.1 General instructions
--------------------------

When running GlusterFS in a non-production environment, be sure to
build it with the following command:

      $ make CFLAGS='-g -O0 -DDEBUG'

   This includes debugging information which will be helpful in getting
backtraces (see below) and also disable optimization. Enabling
optimization can result in incorrect line numbers being reported to gdb.

7.4.2 Volume specification files
--------------------------------

Attach all relevant server and client spec files you were using when
you encountered the bug. Also tell us details of your setup, i.e., how
many clients and how many servers.

7.4.3 Log files
---------------

Set the loglevel of your client and server programs to DEBUG (by
passing the -L DEBUG option) and attach the log files with your bug
report. Obviously, if only the client is failing (for example), you
only need to send us the client log file.

7.4.4 Backtrace
---------------

If GlusterFS has encountered a segmentation fault or has crashed for
some other reason, include the backtrace with the bug report. You can
get the backtrace using the following procedure.

   Run the GlusterFS client or server inside gdb.

      $ gdb ./glusterfs
      (gdb) set args -f client.spec -N -l/path/to/log/file -LDEBUG /mnt/point
      (gdb) run

   Now when the process segfaults, you can get the backtrace by typing:

      (gdb) bt

   If the GlusterFS process has crashed and dumped a core file (you can
find this in / if running as a daemon and in the current directory
otherwise), you can do:

      $ gdb /path/to/glusterfs /path/to/core.<pid>

   and then get the backtrace.

   If the GlusterFS server or client seems to be hung, then you can get
the backtrace by attaching gdb to the process. First get the PID of the
process (using ps), and then do:

      $ gdb ./glusterfs <pid>

   Press Ctrl-C to interrupt the process and then generate the
backtrace.

7.4.5 Reproducing the bug
-------------------------

If the bug is reproducible, please include the steps necessary to do
so. If the bug is not reproducible, send us the bug report anyway.

7.4.6 Other information
-----------------------

If you think it is relevant, send us also the version of FUSE you're
using, the kernel version, platform.


File: user-guide.info,  Node: GNU Free Documentation Licence,  Next: Index,  Prev: Troubleshooting,  Up: Top

Appendix A GNU Free Documentation Licence
*****************************************

                      Version 1.2, November 2002

     Copyright (C) 2000,2001,2002 Free Software Foundation, Inc.
     59 Temple Place, Suite 330, Boston, MA  02111-1307, USA

     Everyone is permitted to copy and distribute verbatim copies
     of this license document, but changing it is not allowed.

  0. PREAMBLE

     The purpose of this License is to make a manual, textbook, or other
     functional and useful document "free" in the sense of freedom: to
     assure everyone the effective freedom to copy and redistribute it,
     with or without modifying it, either commercially or
     noncommercially.  Secondarily, this License preserves for the
     author and publisher a way to get credit for their work, while not
     being considered responsible for modifications made by others.

     This License is a kind of "copyleft", which means that derivative
     works of the document must themselves be free in the same sense.
     It complements the GNU General Public License, which is a copyleft
     license designed for free software.

     We have designed this License in order to use it for manuals for
     free software, because free software needs free documentation: a
     free program should come with manuals providing the same freedoms
     that the software does.  But this License is not limited to
     software manuals; it can be used for any textual work, regardless
     of subject matter or whether it is published as a printed book.
     We recommend this License principally for works whose purpose is
     instruction or reference.

  1. APPLICABILITY AND DEFINITIONS

     This License applies to any manual or other work, in any medium,
     that contains a notice placed by the copyright holder saying it
     can be distributed under the terms of this License.  Such a notice
     grants a world-wide, royalty-free license, unlimited in duration,
     to use that work under the conditions stated herein.  The
     "Document", below, refers to any such manual or work.  Any member
     of the public is a licensee, and is addressed as "you".  You
     accept the license if you copy, modify or distribute the work in a
     way requiring permission under copyright law.

     A "Modified Version" of the Document means any work containing the
     Document or a portion of it, either copied verbatim, or with
     modifications and/or translated into another language.

     A "Secondary Section" is a named appendix or a front-matter section
     of the Document that deals exclusively with the relationship of the
     publishers or authors of the Document to the Document's overall
     subject (or to related matters) and contains nothing that could
     fall directly within that overall subject.  (Thus, if the Document
     is in part a textbook of mathematics, a Secondary Section may not
     explain any mathematics.)  The relationship could be a matter of
     historical connection with the subject or with related matters, or
     of legal, commercial, philosophical, ethical or political position
     regarding them.

     The "Invariant Sections" are certain Secondary Sections whose
     titles are designated, as being those of Invariant Sections, in
     the notice that says that the Document is released under this
     License.  If a section does not fit the above definition of
     Secondary then it is not allowed to be designated as Invariant.
     The Document may contain zero Invariant Sections.  If the Document
     does not identify any Invariant Sections then there are none.

     The "Cover Texts" are certain short passages of text that are
     listed, as Front-Cover Texts or Back-Cover Texts, in the notice
     that says that the Document is released under this License.  A
     Front-Cover Text may be at most 5 words, and a Back-Cover Text may
     be at most 25 words.

     A "Transparent" copy of the Document means a machine-readable copy,
     represented in a format whose specification is available to the
     general public, that is suitable for revising the document
     straightforwardly with generic text editors or (for images
     composed of pixels) generic paint programs or (for drawings) some
     widely available drawing editor, and that is suitable for input to
     text formatters or for automatic translation to a variety of
     formats suitable for input to text formatters.  A copy made in an
     otherwise Transparent file format whose markup, or absence of
     markup, has been arranged to thwart or discourage subsequent
     modification by readers is not Transparent.  An image format is
     not Transparent if used for any substantial amount of text.  A
     copy that is not "Transparent" is called "Opaque".

     Examples of suitable formats for Transparent copies include plain
     ASCII without markup, Texinfo input format, LaTeX input format,
     SGML or XML using a publicly available DTD, and
     standard-conforming simple HTML, PostScript or PDF designed for
     human modification.  Examples of transparent image formats include
     PNG, XCF and JPG.  Opaque formats include proprietary formats that
     can be read and edited only by proprietary word processors, SGML or
     XML for which the DTD and/or processing tools are not generally
     available, and the machine-generated HTML, PostScript or PDF
     produced by some word processors for output purposes only.

     The "Title Page" means, for a printed book, the title page itself,
     plus such following pages as are needed to hold, legibly, the
     material this License requires to appear in the title page.  For
     works in formats which do not have any title page as such, "Title
     Page" means the text near the most prominent appearance of the
     work's title, preceding the beginning of the body of the text.

     A section "Entitled XYZ" means a named subunit of the Document
     whose title either is precisely XYZ or contains XYZ in parentheses
     following text that translates XYZ in another language.  (Here XYZ
     stands for a specific section name mentioned below, such as
     "Acknowledgements", "Dedications", "Endorsements", or "History".)
     To "Preserve the Title" of such a section when you modify the
     Document means that it remains a section "Entitled XYZ" according
     to this definition.

     The Document may include Warranty Disclaimers next to the notice
     which states that this License applies to the Document.  These
     Warranty Disclaimers are considered to be included by reference in
     this License, but only as regards disclaiming warranties: any other
     implication that these Warranty Disclaimers may have is void and
     has no effect on the meaning of this License.

  2. VERBATIM COPYING

     You may copy and distribute the Document in any medium, either
     commercially or noncommercially, provided that this License, the
     copyright notices, and the license notice saying this License
     applies to the Document are reproduced in all copies, and that you
     add no other conditions whatsoever to those of this License.  You
     may not use technical measures to obstruct or control the reading
     or further copying of the copies you make or distribute.  However,
     you may accept compensation in exchange for copies.  If you
     distribute a large enough number of copies you must also follow
     the conditions in section 3.

     You may also lend copies, under the same conditions stated above,
     and you may publicly display copies.

  3. COPYING IN QUANTITY

     If you publish printed copies (or copies in media that commonly
     have printed covers) of the Document, numbering more than 100, and
     the Document's license notice requires Cover Texts, you must
     enclose the copies in covers that carry, clearly and legibly, all
     these Cover Texts: Front-Cover Texts on the front cover, and
     Back-Cover Texts on the back cover.  Both covers must also clearly
     and legibly identify you as the publisher of these copies.  The
     front cover must present the full title with all words of the
     title equally prominent and visible.  You may add other material
     on the covers in addition.  Copying with changes limited to the
     covers, as long as they preserve the title of the Document and
     satisfy these conditions, can be treated as verbatim copying in
     other respects.

     If the required texts for either cover are too voluminous to fit
     legibly, you should put the first ones listed (as many as fit
     reasonably) on the actual cover, and continue the rest onto
     adjacent pages.

     If you publish or distribute Opaque copies of the Document
     numbering more than 100, you must either include a
     machine-readable Transparent copy along with each Opaque copy, or
     state in or with each Opaque copy a computer-network location from
     which the general network-using public has access to download
     using public-standard network protocols a complete Transparent
     copy of the Document, free of added material.  If you use the
     latter option, you must take reasonably prudent steps, when you
     begin distribution of Opaque copies in quantity, to ensure that
     this Transparent copy will remain thus accessible at the stated
     location until at least one year after the last time you
     distribute an Opaque copy (directly or through your agents or
     retailers) of that edition to the public.

     It is requested, but not required, that you contact the authors of
     the Document well before redistributing any large number of
     copies, to give them a chance to provide you with an updated
     version of the Document.

  4. MODIFICATIONS

     You may copy and distribute a Modified Version of the Document
     under the conditions of sections 2 and 3 above, provided that you
     release the Modified Version under precisely this License, with
     the Modified Version filling the role of the Document, thus
     licensing distribution and modification of the Modified Version to
     whoever possesses a copy of it.  In addition, you must do these
     things in the Modified Version:

       A. Use in the Title Page (and on the covers, if any) a title
          distinct from that of the Document, and from those of
          previous versions (which should, if there were any, be listed
          in the History section of the Document).  You may use the
          same title as a previous version if the original publisher of
          that version gives permission.

       B. List on the Title Page, as authors, one or more persons or
          entities responsible for authorship of the modifications in
          the Modified Version, together with at least five of the
          principal authors of the Document (all of its principal
          authors, if it has fewer than five), unless they release you
          from this requirement.

       C. State on the Title page the name of the publisher of the
          Modified Version, as the publisher.

       D. Preserve all the copyright notices of the Document.

       E. Add an appropriate copyright notice for your modifications
          adjacent to the other copyright notices.

       F. Include, immediately after the copyright notices, a license
          notice giving the public permission to use the Modified
          Version under the terms of this License, in the form shown in
          the Addendum below.

       G. Preserve in that license notice the full lists of Invariant
          Sections and required Cover Texts given in the Document's
          license notice.

       H. Include an unaltered copy of this License.

       I. Preserve the section Entitled "History", Preserve its Title,
          and add to it an item stating at least the title, year, new
          authors, and publisher of the Modified Version as given on
          the Title Page.  If there is no section Entitled "History" in
          the Document, create one stating the title, year, authors,
          and publisher of the Document as given on its Title Page,
          then add an item describing the Modified Version as stated in
          the previous sentence.

       J. Preserve the network location, if any, given in the Document
          for public access to a Transparent copy of the Document, and
          likewise the network locations given in the Document for
          previous versions it was based on.  These may be placed in
          the "History" section.  You may omit a network location for a
          work that was published at least four years before the
          Document itself, or if the original publisher of the version
          it refers to gives permission.

       K. For any section Entitled "Acknowledgements" or "Dedications",
          Preserve the Title of the section, and preserve in the
          section all the substance and tone of each of the contributor
          acknowledgements and/or dedications given therein.

       L. Preserve all the Invariant Sections of the Document,
          unaltered in their text and in their titles.  Section numbers
          or the equivalent are not considered part of the section
          titles.

       M. Delete any section Entitled "Endorsements".  Such a section
          may not be included in the Modified Version.

       N. Do not retitle any existing section to be Entitled
          "Endorsements" or to conflict in title with any Invariant
          Section.

       O. Preserve any Warranty Disclaimers.

     If the Modified Version includes new front-matter sections or
     appendices that qualify as Secondary Sections and contain no
     material copied from the Document, you may at your option
     designate some or all of these sections as invariant.  To do this,
     add their titles to the list of Invariant Sections in the Modified
     Version's license notice.  These titles must be distinct from any
     other section titles.

     You may add a section Entitled "Endorsements", provided it contains
     nothing but endorsements of your Modified Version by various
     parties--for example, statements of peer review or that the text
     has been approved by an organization as the authoritative
     definition of a standard.

     You may add a passage of up to five words as a Front-Cover Text,
     and a passage of up to 25 words as a Back-Cover Text, to the end
     of the list of Cover Texts in the Modified Version.  Only one
     passage of Front-Cover Text and one of Back-Cover Text may be
     added by (or through arrangements made by) any one entity.  If the
     Document already includes a cover text for the same cover,
     previously added by you or by arrangement made by the same entity
     you are acting on behalf of, you may not add another; but you may
     replace the old one, on explicit permission from the previous
     publisher that added the old one.

     The author(s) and publisher(s) of the Document do not by this
     License give permission to use their names for publicity for or to
     assert or imply endorsement of any Modified Version.

  5. COMBINING DOCUMENTS

     You may combine the Document with other documents released under
     this License, under the terms defined in section 4 above for
     modified versions, provided that you include in the combination
     all of the Invariant Sections of all of the original documents,
     unmodified, and list them all as Invariant Sections of your
     combined work in its license notice, and that you preserve all
     their Warranty Disclaimers.

     The combined work need only contain one copy of this License, and
     multiple identical Invariant Sections may be replaced with a single
     copy.  If there are multiple Invariant Sections with the same name
     but different contents, make the title of each such section unique
     by adding at the end of it, in parentheses, the name of the
     original author or publisher of that section if known, or else a
     unique number.  Make the same adjustment to the section titles in
     the list of Invariant Sections in the license notice of the
     combined work.

     In the combination, you must combine any sections Entitled
     "History" in the various original documents, forming one section
     Entitled "History"; likewise combine any sections Entitled
     "Acknowledgements", and any sections Entitled "Dedications".  You
     must delete all sections Entitled "Endorsements."

  6. COLLECTIONS OF DOCUMENTS

     You may make a collection consisting of the Document and other
     documents released under this License, and replace the individual
     copies of this License in the various documents with a single copy
     that is included in the collection, provided that you follow the
     rules of this License for verbatim copying of each of the
     documents in all other respects.

     You may extract a single document from such a collection, and
     distribute it individually under this License, provided you insert
     a copy of this License into the extracted document, and follow
     this License in all other respects regarding verbatim copying of
     that document.

  7. AGGREGATION WITH INDEPENDENT WORKS

     A compilation of the Document or its derivatives with other
     separate and independent documents or works, in or on a volume of
     a storage or distribution medium, is called an "aggregate" if the
     copyright resulting from the compilation is not used to limit the
     legal rights of the compilation's users beyond what the individual
     works permit.  When the Document is included in an aggregate, this
     License does not apply to the other works in the aggregate which
     are not themselves derivative works of the Document.

     If the Cover Text requirement of section 3 is applicable to these
     copies of the Document, then if the Document is less than one half
     of the entire aggregate, the Document's Cover Texts may be placed
     on covers that bracket the Document within the aggregate, or the
     electronic equivalent of covers if the Document is in electronic
     form.  Otherwise they must appear on printed covers that bracket
     the whole aggregate.

  8. TRANSLATION

     Translation is considered a kind of modification, so you may
     distribute translations of the Document under the terms of section
     4.  Replacing Invariant Sections with translations requires special
     permission from their copyright holders, but you may include
     translations of some or all Invariant Sections in addition to the
     original versions of these Invariant Sections.  You may include a
     translation of this License, and all the license notices in the
     Document, and any Warranty Disclaimers, provided that you also
     include the original English version of this License and the
     original versions of those notices and disclaimers.  In case of a
     disagreement between the translation and the original version of
     this License or a notice or disclaimer, the original version will
     prevail.

     If a section in the Document is Entitled "Acknowledgements",
     "Dedications", or "History", the requirement (section 4) to
     Preserve its Title (section 1) will typically require changing the
     actual title.

  9. TERMINATION

     You may not copy, modify, sublicense, or distribute the Document
     except as expressly provided for under this License.  Any other
     attempt to copy, modify, sublicense or distribute the Document is
     void, and will automatically terminate your rights under this
     License.  However, parties who have received copies, or rights,
     from you under this License will not have their licenses
     terminated so long as such parties remain in full compliance.

 10. FUTURE REVISIONS OF THIS LICENSE

     The Free Software Foundation may publish new, revised versions of
     the GNU Free Documentation License from time to time.  Such new
     versions will be similar in spirit to the present version, but may
     differ in detail to address new problems or concerns.  See
     `http://www.gnu.org/copyleft/'.

     Each version of the License is given a distinguishing version
     number.  If the Document specifies that a particular numbered
     version of this License "or any later version" applies to it, you
     have the option of following the terms and conditions either of
     that specified version or of any later version that has been
     published (not as a draft) by the Free Software Foundation.  If
     the Document does not specify a version number of this License,
     you may choose any version ever published (not as a draft) by the
     Free Software Foundation.

A.0.1 ADDENDUM: How to use this License for your documents
----------------------------------------------------------

To use this License in a document you have written, include a copy of
the License in the document and put the following copyright and license
notices just after the title page:

       Copyright (C)  YEAR  YOUR NAME.
       Permission is granted to copy, distribute and/or modify this document
       under the terms of the GNU Free Documentation License, Version 1.2
       or any later version published by the Free Software Foundation;
       with no Invariant Sections, no Front-Cover Texts, and no Back-Cover
       Texts.  A copy of the license is included in the section entitled ``GNU
       Free Documentation License''.

   If you have Invariant Sections, Front-Cover Texts and Back-Cover
Texts, replace the "with...Texts." line with this:

         with the Invariant Sections being LIST THEIR TITLES, with
         the Front-Cover Texts being LIST, and with the Back-Cover Texts
         being LIST.

   If you have Invariant Sections without Cover Texts, or some other
combination of the three, merge those two alternatives to suit the
situation.

   If your document contains nontrivial examples of program code, we
recommend releasing these examples in parallel under your choice of
free software license, such as the GNU General Public License, to
permit their use in free software.


File: user-guide.info,  Node: Index,  Prev: GNU Free Documentation Licence,  Up: Top

Index
*****

 [index ]
* Menu:

* alu (scheduler):                       Unify.               (line   6)
* AppArmour:                             Client errors.       (line  59)
* arch:                                  Getting GlusterFS.   (line   6)
* automatic file replication (AFR):      Automatic File Replication.
                                                              (line   6)
* booster:                               Booster.             (line   3)
* commercial support:                    Introduction.        (line  33)
* fcntl:                                 POSIX Locks.         (line   6)
* FDL, GNU Free Documentation License:   GNU Free Documentation Licence.
                                                              (line   6)
* fixed-id (translator):                 Fixed ID.            (line   6)
* GlusterFS client:                      Client.              (line   6)
* GlusterFS mailing list:                Introduction.        (line  28)
* GlusterFS server:                      Server.              (line   6)
* infiniband transport:                  ibverbs.             (line   6)
* InfiniBand, installation:              Pre requisites.      (line  22)
* io-cache (translator):                 IO Cache.            (line   6)
* io-threads (translator):               IO Threads.          (line   6)
* IRC channel, #gluster:                 Introduction.        (line  31)
* libibverbs:                            Pre requisites.      (line  22)
* namespace:                             Unify.               (line 136)
* nufa (scheduler):                      Unify.               (line   6)
* OpenSuSE:                              Client errors.       (line  59)
* posix-locks (translator):              POSIX Locks.         (line   6)
* random (scheduler):                    Unify.               (line   6)
* read-ahead (translator):               Read Ahead.          (line   6)
* record locking:                        POSIX Locks.         (line   6)
* Redhat Enterprise Linux:               Client errors.       (line  41)
* rot-13 (translator):                   ROT-13.              (line   6)
* RPM package:                           Getting GlusterFS.   (line  21)
* rr (scheduler):                        Unify.               (line   6)
* scheduler (unify):                     Unify.               (line   6)
* self heal (AFR):                       Automatic File Replication.
                                                              (line  21)
* self heal (unify):                     Unify.               (line 141)
* stripe (translator):                   Stripe.              (line   6)
* trace (translator):                    Trace.               (line   6)
* Ubuntu package:                        Getting GlusterFS.   (line  26)
* unify (translator):                    Unify.               (line   6)
* write-behind (translator):             Write Behind.        (line   6)
* Z Research, Inc.:                      Introduction.        (line  33)



Tag Table:
Node: Top648
Node: Acknowledgements2304
Node: Introduction3450
Node: Installation and Invocation4769
Node: Pre requisites5053
Node: Getting GlusterFS5992
Ref: Getting GlusterFS-Footnote-17204
Node: Building7252
Node: Running GlusterFS8111
Node: Server8322
Node: Client8965
Node: A Tutorial Introduction10146
Node: Concepts13668
Node: Filesystems in Userspace13883
Node: Translator15773
Node: Volume specification file17963
Node: Translators18117
Node: Storage Translators18420
Ref: Storage Translators-Footnote-119219
Node: POSIX19353
Node: Client and Server Translators20004
Node: Transport modules20480
Node: TCP20971
Node: IB-SDP21132
Node: ibverbs21325
Node: Client protocol22865
Node: Server protocol23234
Node: Clustering Translators23516
Node: Unify23777
Ref: Unify-Footnote-129431
Node: Automatic File Replication29494
Node: Stripe30524
Node: Performance Translators30792
Node: Read Ahead31054
Node: Write Behind32802
Node: IO Threads34211
Node: IO Cache35302
Node: Booster36639
Node: Features Translators37977
Node: POSIX Locks38205
Node: Fixed ID39523
Node: Miscallaneous Translators40009
Node: ROT-1340207
Node: Trace40886
Node: Usage Scenarios42155
Node: Performance48385
Node: Troubleshooting49090
Node: GlusterFS error messages49304
Node: Server errors49403
Node: Client errors50036
Node: GNU Free Documentation Licence54790
Node: Index77239

End Tag Table
